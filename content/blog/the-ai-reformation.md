+++
title = "Sola Computa: The Coming AI Reformation"
date = 2025-10-25
+++

## The Pattern Repeats

In 1517, the printing press enabled direct access to religious texts. Technology that removes intermediaries displaces systems built on intermediation.

Five centuries later, Large Language Models (LLMs) are becoming efficient enough to run on local hardware. When capable AI can run on hardware you own, the economics of computing fundamentally change.

## The Billion Parameter Threshold

Andrej Karpathy speculates that LLM cognitive cores could shrink to around a billion parameters while maintaining sophisticated reasoning. This is the threshold that makes everything else possible.

Current frontier models run at roughly a trillion parameters because they're doing two things: memorizing vast information from training and learning reasoning algorithms. Karpathy calls the second part the "cognitive core"—patterns for problem-solving stripped of excess memorization.

Smaller models forced to rely on retrieval for facts while maintaining strong reasoning would be more useful. The memorization distracts them. When models hit the billion-parameter threshold: hardware becomes consumer-grade, latency becomes real-time, cost structure inverts to electricity vs. subscriptions, and customization becomes practical.

Karpathy suggests 10-20 years. But the direction is clear and improvement compounds.

## Why SaaS Exists

SaaS emerged because maintaining software is expensive. Security patches, dependency updates, infrastructure changes, API versions, compatibility matrices. Organizations paid subscriptions because hiring specialized staff for constant maintenance was more expensive than vendor fees.

But this assumes maintenance requires human expertise. AI changes this assumption fundamentally. When local AI can handle routine maintenance conversationally—monitoring, patching, troubleshooting—the cost structure inverts.

More importantly: AI can self-reference and self-maintain. The model reads its own documentation, understands its own configuration, debugs its own errors, manages the systems that manage it. This recursive capability eliminates the maintenance burden that made SaaS economically necessary.

## The Core vs. The Edge

Not everything will be de-SaaSified. Some services genuinely benefit from centralization: global payment networks, real-time collaboration, specialized datasets.

What changes is the locus of control. You maintain a core operating system layer yourself. Above it, you still use SaaS for specialized functions. But the relationship inverts: services integrate with your infrastructure, not vice versa. You choose what data to share. You maintain the ability to leave without losing context.

The critical difference: your core system works without external permission. If a SaaS provider shuts down, raises prices, or gets acquired, you continue operating. The SaaS layer becomes optional augmentation, not critical dependency.

## Working Backwards: The Technical Requirements

To understand when the shift happens, work backwards from the end state. What technical conditions must be satisfied for individuals and organizations to run sovereign infrastructure?

### 1. Local Model Execution

**Required state**: Billion-parameter models running on consumer hardware with acceptable latency. The cognitive core is small enough to load into RAM, fast enough for real-time interaction, capable enough for system administration and development tasks.

**Tipping point**: When local models can write production code, debug systems, and handle infrastructure management without constant human oversight. Not just autocomplete—actual autonomous system administration.

### 2. AI-Generated Operating Systems

**Required state**: Operating systems generated by AI, customized to user requirements, maintainable by AI. Not forking existing systems—generating them from specifications.

**Why this matters**: True sovereignty requires control over the full stack, including the kernel. If your OS is maintained by a vendor, you have dependency and vulnerability. If your AI can generate and maintain the OS, you have sovereignty.

**Technical path**:

- AI reaches capability to write system-level code reliably
- Formal verification tools advance to prove AI-generated code is safe
- Modular OS architectures emerge that AI can reason about
- Composition becomes more important than monolithic design

**Tipping point**: When AI can generate a bootable, secure, functional operating system from high-level requirements in hours or days. When it can maintain that OS indefinitely—patching vulnerabilities, optimizing performance, adding capabilities—without human intervention.

### 3. Storage Economics

**Current state**: Already there. Storage is cheap. A 20TB drive costs $300. Local storage for most individual and small business use cases is economically viable.

**What remains**: Distributed storage for backup and redundancy. IPFS, Arweave, Filecoin provide this. Integration with local AI so systems automatically handle replication, verification, and recovery.

### 4. Distributed Systems of Record with Zero-Knowledge Proofs

**Required state**: Systems where you can prove facts about data without revealing the data itself. Critical for maintaining privacy while using distributed infrastructure.

**Why this matters**:

- Identity: Prove you're authorized without revealing your identity
- Transactions: Prove payment occurred without revealing amounts or parties
- Credentials: Prove qualifications without revealing personal information
- State: Maintain verifiable records without making everything public

**Technical path**:

- ZK-SNARK and ZK-STARK systems mature
- AI learns to generate zero-knowledge circuits from specifications
- Integration layers connect local systems to distributed registries
- Standards emerge for common use cases

**Tipping point**: When AI can automatically generate zero-knowledge proofs for any data structure or computation you specify. When privacy-preserving distributed state becomes as easy to implement as a local database.

### 5. Energy Economics

**Current state**: Already acceptable. Smaller models require minimal energy. A billion-parameter model running inference uses less power than a gaming PC under load.

**What this enables**: Always-on local AI without prohibitive electricity costs. Your model runs continuously, handling tasks as they arise.

**Comparison**: Running local AI 24/7 costs roughly $10-30/month in electricity. Compare to SaaS subscriptions for equivalent functionality: easily $500-5000/month.

### 6. Legal Framework for Modification Rights

**Required state**: Either repeal of anti-jailbreaking laws, widespread non-enforcement, or jurisdictional fragmentation where some regions permit modification.

**Why this matters**: Technical capability without legal permission creates risk. Organizations and individuals need certainty they can modify their own infrastructure without legal liability.

**Possible paths**:

- Legislative reform (right to repair movements expanding to software)
- Trade agreement collapse (removing coordination mechanism for restrictions)
- Jurisdictional arbitrage (some regions permit what others prohibit)
- Civil disobedience (widespread violation makes enforcement impractical)

### 7. Interoperability Standards

**Required state**: Open standards for common operations. Not universal standards—that's neither possible nor desirable—but widely-adopted protocols for basic functions.

**Why this matters**: Sovereignty requires the ability to leave any platform. This requires data portability, API compatibility, and format translation.

**Technical path**:

- AI learns to translate between formats automatically
- Open-source implementations of common protocols proliferate
- Network effects favor systems that interoperate
- Governments mandate data portability in key sectors

**Tipping point**: When moving between platforms becomes routine rather than exceptional. When AI can handle translation automatically and reliably.

### 8. Cryptographic Infrastructure

**Required state**: Decentralized E2EE infrastructure. Public keys on distributed ledgers. No trusted intermediaries required for secure communication.

**Why this matters**: Local sovereignty without communication privacy is incomplete. You need to exchange data with others without intermediaries who can intercept, log, or be compelled to surveil.

**Technical path**:

- Blockchain-based identity systems mature
- Distributed key registries become standard
- AI handles encryption complexity automatically
- Forward secrecy and key rotation become default

**Tipping point**: When secure communication requires no central authority. When your AI can establish encrypted channels with any other AI using only public infrastructure.

## Self-Sovereignty in a Digital World

As systems become more capable, self-sovereignty becomes increasingly critical. Not because the technology is dangerous, but because the world becomes more digital.

Every aspect of life mediated by software becomes subject to whoever controls that software. If your identity is managed by a corporation, they control your identity. If your financial transactions require their approval, they control your finances. If your communications route through their servers, they control your ability to communicate.

In a pre-digital world, sovereignty was physical. You controlled your property, your movement, your associations. Digital sovereignty is different but equally fundamental: controlling your computational infrastructure, your data, your digital identity.

More capable AI amplifies the stakes in both directions. If AI-level systems are controlled by a few corporations or governments, the power concentration is unprecedented. They can deny service, modify behavior, surveil activity, or simply shut things off. The killswitches already exist—John Deere tractors, Apple phones, network equipment with CALEA backdoors. More capable AI makes those killswitches more effective and harder to circumvent.

But if individuals run capable systems locally, the capability concentration reverses. You can build, modify, and maintain arbitrarily complex infrastructure without specialized knowledge. The barrier to technical capability approaches zero. Small groups can build what previously required large organizations.

The choice isn't between AI with sovereignty or AI without it. More capable systems are coming regardless. The choice is who controls them.

Current trajectory: capability is developed by large labs, deployed as services, accessed through APIs, subject to terms of service and acceptable use policies. This is the SaaS model extended to intelligence itself. You rent capability, follow their rules, accept their updates, lose access when they decide.

Alternative trajectory: capable models run locally, owned by users, modified freely, operating under their control. The capability exists locally. The intelligence serves its operator, not a distant corporation.

This isn't anti-commercial. Services will still exist. Specialized models, proprietary datasets, compute-intensive tasks—plenty of room for commercial offerings. But the base layer of computational capability runs locally. You're not renting intelligence; you own it.

## Technology Sovereignty as Prerequisite

The technical requirements aren't independent. They form a stack:

**Base layer**: Local AI execution (billion-parameter models on consumer hardware)

**System layer**: AI-generated operating systems (full stack under your control)

**Storage layer**: Local + distributed storage (data you own, backed up without central authorities)

**State layer**: Distributed records with zero-knowledge proofs (verifiable facts without exposing data)

**Communication layer**: Decentralized E2EE (secure channels without intermediaries)

**Integration layer**: Interoperability standards + AI translation (move between systems freely)

**Legal layer**: Modification rights (ability to control your own infrastructure without liability)

**Energy layer**: Economics that make always-on local AI practical (already achieved)

Each layer enables the ones above. Without local AI execution, nothing else matters. Without AI-generated OS, you have dependency on vendor systems. Without distributed state, you lack coordination mechanisms. Without encryption, you lack privacy. Without interoperability, you lack exit options. Without legal protection, you have liability risk. Without reasonable energy costs, the economics don't work.

But when all layers are satisfied, something fundamental shifts: technology serves its users rather than surveilling them. Devices obey their owners rather than manufacturers. Systems operate under user control rather than vendor discretion.

## The Tipping Point

The shift happens when running sovereign infrastructure becomes easier than using SaaS. Not just cheaper—easier.

Current SaaS advantage: you don't need to manage complexity. Someone else handles it. You pay for convenience.

Future local advantage: AI handles complexity for you. You pay nothing ongoing. And you control everything.

The crossover happens when AI reaches the capability threshold where system administration becomes conversational. Where maintaining infrastructure requires directing rather than executing. Where technical complexity stops being a barrier because your AI handles technical work.

For sophisticated users, this already happened. They run local models, manage their own infrastructure, avoid vendor lock-in. As models approach the billion-parameter threshold, the crossover reaches progressively less technical users.

Eventually: anyone can manage sophisticated infrastructure by describing needs conversationally. Not because they gain technical knowledge, but because AI handles technical complexity.

This is the reformation: direct access to computational capability, without intermediaries. The printing press unbundled access to texts. Personal computers unbundled information processing. AI unbundles creation itself—including the creation of the infrastructure that runs AI.

## What Happens Next

We're early. Models are capable but limited. But trajectory is clear and improvement compounds.

The transition takes years. Some attempts fail. Some "open" platforms recreate centralization. Some blockchain systems prove impractical. Messy evolution, not clean revolution.

But the fundamental shift is underway. The technology exists and improves exponentially. Different regions move at different speeds. Some embrace sovereignty as economic strategy. Others resist until economics make resistance futile.

In 1517, technology enabled direct access to texts previously controlled by institutions. In 2025, technology enables direct access to computational capability previously controlled by platforms.

The shift isn't powered by permission. It's powered by technology that makes permission irrelevant.

Your infrastructure should serve you. Your devices should obey you. Your systems should operate under your control.

That's not radicalism. That's technology sovereignty. And it's becoming technically feasible, economically viable, and politically necessary.
